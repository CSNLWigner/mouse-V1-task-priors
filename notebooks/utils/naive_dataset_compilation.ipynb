{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "192717f6-ed75-4f41-a6ae-0e6c736ab24e",
   "metadata": {},
   "source": [
    "# Naive dataset compilation\n",
    "We have received data for naive animals from the Corbo. To access the data with the tools we've developed, we need to follow the workflow we established for compiling data from `DATASET1`. The workflow is rough the following:\n",
    "1. Create SQL database from CellTrialTable\n",
    "2. Create index on `Experiment` names in the SQL database\n",
    "3. Convert the SQL database to experiment specific CSVs\n",
    "4. Change permisions of the directory holding the CSVs\n",
    "5. Use MATLAB to decode data in experiment specific CSVs to HDF5 files\n",
    "\n",
    "We'll also create the `ExperimentTable` dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f503eac7-a4b5-422f-9727-a093f5012bad",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e59ee72-75db-428d-a909-0d971d96a229",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../../\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a8f7e6-fdca-426e-8c0f-a57ee5aeb2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL imports\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# `ExperimentTable` creation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# CSV creation\n",
    "from src.data_compilation import NAIVE\n",
    "from src.data_compilation import query_CellTrialTable_dataframe, check_CellTrialTable_existence, save_CellTrialTable_df\n",
    "from src.data_compilation import retrieve_experiment_stats, compute_CellTrialTable_df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed60b8c-df95-48cf-aba9-d0d418727312",
   "metadata": {},
   "source": [
    "## Create SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05fb684-643b-4e05-bb8b-b0428ad539f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sqlite_db_from_csv(csv_file, db_file, table_name):\n",
    "    \"\"\"\n",
    "    Create an SQLite database from a CSV file, preserving all columns and column types.\n",
    "    \n",
    "    Args:\n",
    "    - csv_file (str): Path to the CSV file.\n",
    "    - db_file (str): Path to the SQLite database file.\n",
    "    - table_name (str): Name of the table to create in the SQLite database.\n",
    "    \"\"\"\n",
    "    # Step 1: Read a sample of the CSV to infer the schema\n",
    "    sample_size = 1000  # Number of rows to read for inferring the schema\n",
    "    sample_df = pd.read_csv(csv_file, nrows=sample_size)\n",
    "    \n",
    "    # Step 2: Create a dictionary mapping pandas dtypes to SQLite types\n",
    "    dtype_mapping = {\n",
    "        'object': 'TEXT',\n",
    "        'int64': 'INTEGER',\n",
    "        'float64': 'REAL',\n",
    "        'datetime64[ns]': 'TEXT',  # Dates can be stored as TEXT in SQLite\n",
    "        'bool': 'INTEGER'  # SQLite does not have a separate BOOLEAN type\n",
    "    }\n",
    "    \n",
    "    # Step 3: Infer the SQLite column types based on the sample\n",
    "    column_types = {}\n",
    "    for column, dtype in sample_df.dtypes.items():\n",
    "        column_types[column] = dtype_mapping.get(str(dtype), 'TEXT')  # Default to TEXT if dtype is not in mapping\n",
    "    \n",
    "    # Step 4: Create the SQLite table based on the inferred schema\n",
    "    columns_with_types = ', '.join([f'\"{col}\" {dtype}' for col, dtype in column_types.items()])\n",
    "    create_table_sql = f'CREATE TABLE IF NOT EXISTS {table_name} ({columns_with_types});'\n",
    "    \n",
    "    # Step 5: Connect to SQLite database and create the table\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(create_table_sql)\n",
    "    conn.commit()\n",
    "    \n",
    "    print(f\"Table '{table_name}' created successfully with columns: {list(column_types.keys())}\")\n",
    "    \n",
    "    # Step 6: Read and insert the CSV data into SQLite in chunks\n",
    "    chunk_size = 100000  # Number of rows per chunk (adjust based on your memory constraints)\n",
    "    for chunk in tqdm(pd.read_csv(csv_file, chunksize=chunk_size)):\n",
    "        chunk.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "\n",
    "    # Step 7: Close the connection\n",
    "    conn.close()\n",
    "    print(f\"Data from '{csv_file}' has been successfully imported into '{db_file}' as table '{table_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992cacfc-d716-474b-8511-96e46b8a6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = '/home/jovyan/work/task-priors/data/Naive_CellTrialTable.csv'\n",
    "db_file = '/home/jovyan/work/task-priors/data/Naive_CellTrialTable.db'\n",
    "table_name = 'CellTrialTable'  # Name of the table in the SQLite database\n",
    "\n",
    "create_sqlite_db_from_csv(csv_file, db_file, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75f287-5c4e-4de0-8492-09178e6463ca",
   "metadata": {},
   "source": [
    "## Create SQL index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b52bf-4fef-44ea-b1cf-6d888678642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('/home/jovyan/work/task-priors/data/Naive_CellTrialTable.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_experiment ON CellTrialTable (Experiment);\")\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e456e6ae-ed48-4528-8103-6b7cbe0f7751",
   "metadata": {},
   "source": [
    "## Create `ExperimentTable`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d241cd3-f05c-4f64-b88b-a893f6405774",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_celltable = pd.read_csv(NAIVE['CellTable_path'])\n",
    "df_trialtable = pd.read_csv(NAIVE['TrialTable_path'])\n",
    "tables = df_celltable, df_trialtable\n",
    "\n",
    "experiment_ids = list(df_trialtable['Experiment'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f046067f-e58b-4705-ab4b-a1ccd52dbda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_info = []\n",
    "\n",
    "for id_ in experiment_ids:\n",
    "    df_experiment = df_trialtable[df_trialtable['Experiment'] == id_]\n",
    "\n",
    "    mouse = id_[:3]\n",
    "    behav_cond = df_experiment['Behav_Cond'].unique()[0]\n",
    "    task_stim = np.sort(df_experiment[df_experiment['Block'] == 'Visual']['Visual_Stim'].unique())\n",
    "    go_stim = task_stim[0]\n",
    "    nogo_stim = task_stim[1]\n",
    "\n",
    "    experiment_info.append({\n",
    "        'Experiment': id_,\n",
    "        'Mouse': mouse,\n",
    "        'Day': int(behav_cond[1]),\n",
    "        'Behav_Cond': behav_cond,\n",
    "        'Go_stim': go_stim,\n",
    "        'NoGo_stim': nogo_stim,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e4063-2a4e-47ca-88cb-16812ab7d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiments = pd.DataFrame(experiment_info)\n",
    "df_experiments.to_csv('./data/Naive_ExperimentTable.csv')\n",
    "df_experiments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3645fd37-89b2-4fc2-b659-488fc2c1eec4",
   "metadata": {},
   "source": [
    "## Create CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fef234-7a59-42ef-adac-cba0a9ec755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment_id in tqdm(experiment_ids):\n",
    "    try:\n",
    "        check_CellTrialTable_existence(experiment_id, DATASET=NAIVE,)\n",
    "    except FileExistsError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        continue\n",
    "    \n",
    "    df_experiment = query_CellTrialTable_dataframe(experiment_id, DATASET=NAIVE,)\n",
    "    \n",
    "    experiment_stats = retrieve_experiment_stats(experiment_id, tables,)\n",
    "    db_experiment_stats = compute_CellTrialTable_df_stats(df_experiment)\n",
    "    assert experiment_stats == db_experiment_stats, f'Stats for {experiment_id} do not match'\n",
    "\n",
    "    save_CellTrialTable_df(df_experiment, DATASET=NAIVE,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090947a-d0ca-444a-9080-6cfa1de524db",
   "metadata": {},
   "source": [
    "## Set directory permisions\n",
    "The MATLAB account needs permision to write and delete files on the directory containing the csv. Set the permision like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c84166-1ef5-4cf8-b11b-9d40d8c164e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%chmod -R 777 /home/ktmurray/task-priors/data/Naive_CellTrialTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a195255-d1da-4c09-aa54-0cb43c59e7b4",
   "metadata": {},
   "source": [
    "Note that this will not work in a Jupyter notebook run through a docker image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
